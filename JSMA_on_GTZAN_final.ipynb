{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"JSMA_on_GTZAN_final.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"VU98FwVjIxrC"},"source":["Disable eager execution to solve tf version related issue.\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UDnKnT1bH13K","executionInfo":{"status":"ok","timestamp":1628772805315,"user_tz":-360,"elapsed":441,"user":{"displayName":"Tasneem Sumaiya","photoUrl":"","userId":"05522463354673958724"}},"outputId":"13240f3b-2f97-49c2-fc85-dfd5d91f7a2f"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"nEMYIpQARRLI"},"source":["import tensorflow.compat.v1 as tf\n","tf.compat.v1.disable_eager_execution()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hO3hVwM5I0xq"},"source":["Imports\n"]},{"cell_type":"code","metadata":{"id":"b9eO-8k1CvV_"},"source":["import os\n","import cv2\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import confusion_matrix, accuracy_score\n","from keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.utils import to_categorical"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Y18SYh4IM_zP"},"source":["Classifier class"]},{"cell_type":"code","metadata":{"id":"Hnb4HkM5Rhtx"},"source":["INPUT_DIM = 32\n","NUM_OF_CLASSES = 10\n","\n","class CNNet(object):\n","  \n","  def __init__(self, learning_rate=0.001, input_dim = 32, num_class=10):\n","    \n","    # Make hyperparameters instance variables. \n","    self.learning_rate = learning_rate\n","    self.num_class = num_class\n","    self.input_dim = input_dim\n"," \n","    self.initializer = tf.keras.initializers.glorot_uniform()\n","    self.optimizer = tf.train.AdamOptimizer(self.learning_rate)\n","    \n","    # Set Random seed for Tensorflow.\n","    self.random_seed = 42\n","    tf.set_random_seed(self.random_seed)\n","\n","\n","  def network(self, X, activations=False):\n","    \n","    with tf.variable_scope('network', initializer=self.initializer):\n","      \n","        # Define the layers.\n","        self.layers = [\n","            \n","            tf.layers.Conv2D(filters=16, kernel_size=3,\n","                                     strides=(1, 1), activation='relu',padding='SAME'),\n","            \n","            tf.layers.Conv2D(filters=32, kernel_size=3,\n","                                     strides=(2, 2), activation='relu'),\n","            tf.keras.layers.Conv2D(filters=64, kernel_size=3,\n","                                     strides=(2, 2), activation='relu'),\n","            tf.keras.layers.Flatten(),\n","            tf.keras.layers.Dense(self.num_class)\n","        ]\n","        \n","        # Store activations for investigation later.\n","        activations_list = []\n","        \n","        # Forward pass loop, store intermediate activations.\n","        out = X\n","        for layer in self.layers:\n","          out = layer(out)\n","          activations_list.append(out)\n","        \n","        if activations:\n","          return out, activations_list\n","        else:\n","          return out, tf.nn.softmax(out)\n","\n","  def model(self, X, y):\n","\n","    # Get the logits from the network.\n","    out_logits, _ = self.network(X)\n","   \n","    # Calculate Cross Entropy loss.\n","    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(\n","            labels=y, logits=out_logits))\n","    \n","    \n","    # Perform backprop wrt loss and update network variables.\n","    # Instead of doing optimizer.minimize(loss), explicitly defining\n","    # which variables are trained.\n","    grads = self.optimizer.compute_gradients(loss)\n","    \n","    vars_list = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \n","                                  scope=\"network\")\n","    grad_list = [(g, v) for g, v in grads if v in vars_list]\n","    optimize_op = self.optimizer.apply_gradients(grad_list)\n","    \n","    return loss, optimize_op, out_logits\n","  \n","  def metrics(self, y, logits, verbose=True):\n","    \n","    # Get prediction values and flatten.\n","    y = np.argmax(y, axis=1).flatten()\n","    y_ = np.argmax(logits, axis=1).flatten()\n","\n","    confusion = confusion_matrix(y_true=y, y_pred=y_)\n","    accuracy = accuracy_score(y_true=y, y_pred=y_)\n","    \n","    if verbose:\n","      print (\"accuracy score: \", accuracy) \n","      \n","    return accuracy\n","  \n","  def train(self, train_X, train_y, test_X, test_y, \n","            batch_size=256, epochs=100):\n","    \n","    # Clear deafult graph stack and reset global graph definition.\n","    tf.reset_default_graph()\n","    \n","    # GPU config.  \n","    config = tf.ConfigProto()\n","    config.gpu_options.allow_growth=True\n","    \n","    # Placeholders for tensors.\n","    X = tf.compat.v1.placeholder(shape=[None, self.input_dim, self.input_dim, 3], dtype=tf.float32)\n","    y = tf.compat.v1.placeholder(shape=[None, self.num_class], dtype=tf.float32)\n","    \n","    # Get the ops for training the model.\n","    loss, optimize, out_logits = self.model(X, y)\n","     \n","    self.saver =  tf.compat.v1.train.Saver()\n","    \n","    # Initialize session.\n","    with tf.Session(config=config) as sess:\n","      \n","      # Initialize the variables in the graph.\n","      sess.run(tf.global_variables_initializer())\n","      sess.run(tf.local_variables_initializer())\n","      \n","      # Stochastic Gradient Descent loop.\n","      for step in range(epochs):\n","        \n","        # Total number of batch and start index.\n","        num_train_batches, start = int(train_X.shape[0]/batch_size), 0\n","\n","        for _ in range(num_train_batches):\n","          \n","            # Indexes for batch selection.\n","            end = start + batch_size         \n","            limit = end if end < train_X.shape[0] else train_X.shape[0]\n","            idx = np.arange(start, limit)\n","            \n","            # Run optimization op with batch.\n","            _, step_loss = sess.run([optimize, loss], \n","                                    {X: train_X[idx], y: train_y[idx]})\n","            start = end\n","        \n","        print('='*80+'\\nEpoch: {0} Training Loss: {1}'.format(step, step_loss))\n","        \n","        # Get probabilities and report metrics.\n","        probs = sess.run(tf.nn.softmax(out_logits), {X: test_X, y: test_y})\n","        acc = self.metrics(test_y, probs)\n","        \n","        self.saver.save(sess, \"model.ckpt\")\n","        \n","      # Get and save representation space for training set.\n","      probs = sess.run(out_logits, {X: train_X})\n","      np.save('representations.npy', probs)\n","      \n","      return step_loss, acc\n","\n","  def predict(self, X_test, logits=False, reps=False):\n","    \n","    tf.reset_default_graph()\n","    tf.set_random_seed(42)\n","\n","    X =  tf.compat.v1.placeholder(shape=[None, self.input_dim, self.input_dim, 3], dtype=tf.float32)\n","    \n","    # Get the ops for running inference on the model.\n","    out_logits, out_probs = self.network(X)\n","    \n","    saver = tf.compat.v1.train.Saver()\n","    # Initialize a new session on the graph.\n","    with tf.Session() as sess:\n","      \n","        # Load the trained model into the session to run inference.\n","        saver.restore(sess, \"model.ckpt\")\n","        # Get \n","        rep_logits, probs = sess.run([out_logits, out_probs], {X: X_test})\n","    \n","    preds = np.argmax(probs, axis=1).flatten()\n","    if logits:\n","      return preds, probs\n","    elif reps:\n","      return preds, rep_logits\n","    else:\n","      return preds"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"caGVUNQ2JId0"},"source":["## Training a CNN on Medical MNIST"]},{"cell_type":"markdown","metadata":{"id":"1JGoXoXRLsjR"},"source":["**Methods**"]},{"cell_type":"markdown","metadata":{"id":"ftMqWhR2Lx8m"},"source":["This method convert training/ testing iterator to array"]},{"cell_type":"code","metadata":{"id":"n52bJZ8rKFPK"},"source":["def convertIteratorToArray(data_generator):\n","  data_list = []\n","  batch_index = 0\n","\n","  while batch_index <= data_generator.batch_index:\n","      data = data_generator.next()\n","      data_list.append(data[0])\n","      batch_index = batch_index + 1\n","\n","  # now, data_array is the numeric data of whole images\n","  \n","  converted_array = np.asarray(data_list)\n","  return converted_array"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"i8rO17elLX2p"},"source":["This method convert the class labels to an array"]},{"cell_type":"code","metadata":{"id":"GoQKvWBUV-Ei"},"source":["def processLabels(data_generator):\n","  \n","  data_list = []\n","  batch_index = 0\n","\n","  while batch_index <= data_generator.batch_index:\n","      data = data_generator.next()\n","      item = data[1].reshape(10)\n","      data_list.append(item)\n","      batch_index = batch_index + 1\n","\n","  # now, data_array is the numeric data of whole images\n","  converted_array = np.asarray(data_list)\n","  return converted_array\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qZ59QGQWNIAK"},"source":["**Data Preporcessing**"]},{"cell_type":"markdown","metadata":{"id":"-7Aw2Hx_Jc8g"},"source":["Creating ImageDataGenerator for Loading Training Images "]},{"cell_type":"code","metadata":{"id":"n45iYjOAB6LP"},"source":["datagen = ImageDataGenerator(validation_split=0.33)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UbExdyuuJ3cK"},"source":["Load and iterate training dataset"]},{"cell_type":"code","metadata":{"id":"Iwbq-FTUHUYJ"},"source":["dataset_path = \"/content/drive/MyDrive/Research/GTZAN_Adversarial/images_original/\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"s90C82KWCvcb","executionInfo":{"status":"ok","timestamp":1628772806368,"user_tz":-360,"elapsed":9,"user":{"displayName":"Tasneem Sumaiya","photoUrl":"","userId":"05522463354673958724"}},"outputId":"906d255c-934d-44b9-eb22-a21152530cf8"},"source":["\n","train_generator = datagen.flow_from_directory(\n","    directory=dataset_path,\n","    target_size=(INPUT_DIM, INPUT_DIM),\n","    color_mode=\"rgb\",\n","    batch_size=1,\n","    subset=\"training\",\n","    class_mode=\"categorical\",\n","    shuffle=True,\n","    seed=42\n",")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Found 670 images belonging to 10 classes.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"cy-zwROqJ86V"},"source":["Load and iterate test dataset"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TTNGUsdwKBzP","executionInfo":{"status":"ok","timestamp":1628772806834,"user_tz":-360,"elapsed":472,"user":{"displayName":"Tasneem Sumaiya","photoUrl":"","userId":"05522463354673958724"}},"outputId":"21070688-4ad0-4e66-b4a3-1fe9263249e9"},"source":["test_generator = datagen.flow_from_directory(\n","    directory=dataset_path,\n","    target_size=(INPUT_DIM, INPUT_DIM),\n","    color_mode=\"rgb\",\n","    batch_size=1,\n","    subset=\"validation\",\n","    class_mode=\"categorical\",\n","    shuffle=True,\n","    seed=42\n",")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Found 329 images belonging to 10 classes.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"FY7b1rDlLnQJ"},"source":["Get labels of training/ testing data"]},{"cell_type":"code","metadata":{"id":"VFKokOL_QGb2"},"source":["train_labels = processLabels(train_generator)\n","test_labels = processLabels(test_generator)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_HLlyip1L8Ms"},"source":["Converting training/testing iterators to an array"]},{"cell_type":"code","metadata":{"id":"q-adyDaOLFvG"},"source":["train_array = convertIteratorToArray(train_generator)\n","test_array = convertIteratorToArray(test_generator)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iKbK31HEOQQM"},"source":["# Reshape to 4 dimensions and bring intensity to [0,1].\n","x_train, x_test = train_array.reshape(-1,INPUT_DIM,INPUT_DIM,3)/255., test_array.reshape(-1,INPUT_DIM,INPUT_DIM,3)/255.\n","y_train_oh, y_test_oh = train_labels, test_labels\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"olg24JFHgc5u"},"source":["Model training"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NGt0myACXw-b","executionInfo":{"status":"ok","timestamp":1628772820146,"user_tz":-360,"elapsed":3940,"user":{"displayName":"Tasneem Sumaiya","photoUrl":"","userId":"05522463354673958724"}},"outputId":"451ae5ea-9e71-4ee4-90d8-6b31728b18c3"},"source":["# Train the model for 15 epochs.\n","gtzan_classifier = CNNet()\n","gtzan_classifier.train(x_train, y_train_oh, x_test, y_test_oh, epochs=10)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["================================================================================\n","Epoch: 0 Training Loss: 2.3252391815185547\n","accuracy score:  0.10638297872340426\n","================================================================================\n","Epoch: 1 Training Loss: 2.3090906143188477\n","accuracy score:  0.10638297872340426\n","================================================================================\n","Epoch: 2 Training Loss: 2.2965474128723145\n","accuracy score:  0.0972644376899696\n","================================================================================\n","Epoch: 3 Training Loss: 2.287534475326538\n","accuracy score:  0.0972644376899696\n","================================================================================\n","Epoch: 4 Training Loss: 2.280410051345825\n","accuracy score:  0.11550151975683891\n","================================================================================\n","Epoch: 5 Training Loss: 2.273501396179199\n","accuracy score:  0.1033434650455927\n","================================================================================\n","Epoch: 6 Training Loss: 2.266392707824707\n","accuracy score:  0.0911854103343465\n","================================================================================\n","Epoch: 7 Training Loss: 2.259554862976074\n","accuracy score:  0.0972644376899696\n","================================================================================\n","Epoch: 8 Training Loss: 2.252469301223755\n","accuracy score:  0.10030395136778116\n","================================================================================\n","Epoch: 9 Training Loss: 2.2438135147094727\n","accuracy score:  0.10638297872340426\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["(2.2438135, 0.10638297872340426)"]},"metadata":{"tags":[]},"execution_count":505}]},{"cell_type":"markdown","metadata":{"id":"djocRKfpggai"},"source":["# Jacobian Based Saliency Map Attack"]},{"cell_type":"markdown","metadata":{"id":"EGcjs1LMh3lr"},"source":["Methods "]},{"cell_type":"code","metadata":{"id":"qVCFa0_OurIi"},"source":["def saliency_map(X, dtdx, dodx, eps, cmin, cmax):\n","  \"\"\"\n","  Saliency map function that returns score for each input dimension.\n","  \"\"\"\n","  # Check initial conditions.\n","  c1 = tf.logical_or(eps < 0, X < cmax)\n","  c2 = tf.logical_or(eps > 0, X > cmin)\n","  \n","  # Check saliency map conditions.\n","  c3 = dtdx >= 0\n","  c4 = dodx <= 0\n","  \n","  # Get 1D score by doing logical AND between conditions.\n","  cond = tf.cast(tf.reduce_all([c1, c2, c3, c4], axis=0),dtype=tf.float32)\n","  \n","  score = cond * (dtdx * tf.abs(dodx))\n","  \n","  # Return score for each pixel\n","  score = tf.reshape(score, shape=[1, 3072])# 32*32*3 = 3072\n","  \n","  return score"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"y6AoIc5IvAX2"},"source":["def jacobian_matrix(y, x, n_class):\n","  \"\"\"\n","  Calculate jacobian of logits wrt input.\n","  \"\"\"\n","  for i in range(n_class):\n","      if i==0:\n","          j = tf.gradients(y[i], x)\n","      else:\n","          j = tf.concat([j, tf.gradients(y[i], x)],axis=0)\n","  return j"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"V2wZYQ5OvDHU"},"source":["def jsma(X_adv, target_y, model, eps, cmin=0.0, cmax=1.0):\n","  \"\"\"\n","  Implementation of JSMA method to generate adversarial images.\n","  \"\"\"\n","  # Get model logits and probs for the input.\n","  logits, probs = model(tf.reshape(X_adv, shape=(-1,32,32,3)))\n","  \n","  # Get model prediction for inputs.\n","  y_ind = tf.argmax(probs[0])\n","  \n","  # Calculate jacobian matrix of logits wrt to input.\n","  jacobian = jacobian_matrix(tf.reshape(logits, (-1,)), X_adv, 10)\n","\n","  # Get the gradient of logits wrt to prediction and target.\n","  grad_input, grad_target = jacobian[y_ind], jacobian[target_y]\n","  grad_other = grad_input - grad_target\n","  \n","  # Compute saliency score for each dimension.\n","  score = saliency_map(X_adv, grad_target, grad_other, eps, cmin, cmax)\n","\n","  # Select dimension of input and apply epsilon value.\n","  idx = tf.argmax(score, axis=1)\n","  pert = tf.one_hot(idx, 3072, on_value=eps, off_value=0.0)\n","  pert = tf.reshape(pert, shape=tf.shape(X_adv))\n","\n","  X_adv = tf.clip_by_value(X_adv + pert, cmin, cmax)\n","\n","  return X_adv, pert"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7TPeVz3UvGS8"},"source":["def generate_jsma(model, X, target, eps=1.0, epochs=50):\n","  \"\"\"\n","  Run JSMA on input image for `epochs` number of times.\n","  \"\"\"\n","  tf.reset_default_graph()\n","  tf.set_random_seed(42)\n","  \n","  # Placeholder for single image.\n","  X_p =  tf.compat.v1.placeholder(shape=[32, 32, 3], dtype=tf.float32)\n","  \n","  # Op for one iteration of jsma.\n","  adv_op = jsma(X_p, target_y=target, model=model, eps=eps)\n","\n","  digit = X.reshape(32,32,3)\n","\n","  with tf.Session() as sess:\n","    tf.compat.v1.train.Saver().restore(sess, \"model.ckpt\")\n","    for i in range(epochs):\n","      digit, pert_iter = sess.run(adv_op, {X_p: digit})\n","      \n","  pert = digit - X\n","      \n","  return digit.reshape(32,32,3), pert.reshape(32,32,3)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9Ri-Cgvgmm-y"},"source":["Generate adversarial image and pertubations using JSMA method."]},{"cell_type":"code","metadata":{"id":"FBdDcJ9hvKSV"},"source":["\n","advs_jsma, perts_jsma = [], []\n","\n","for imgs in x_train:\n","  digit,pert = generate_jsma(gtzan_classifier.network,\n","                        imgs,\n","                        target=0,\n","                        eps=0.5,\n","                        epochs=100)\n","  advs_jsma.append(digit)\n","  perts_jsma.append(pert)\n","\n","# Get predictions and confidence for adversarial inputs\n","preds_jsma, probs_jsma = gtzan_classifier.predict(\n","    np.array(advs_jsma).reshape(len(x_train),32,32,3), logits=True)\n","\n","# Convert predictions and probabilities into lists.\n","preds_jsma = preds_jsma.tolist()\n","probs_jsma = np.max(probs_jsma, axis=1).tolist()\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"72ivLwYKmtnq"},"source":["Saving Output Images"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KsNgcdhuwqdW","executionInfo":{"status":"ok","timestamp":1628786548713,"user_tz":-360,"elapsed":31,"user":{"displayName":"Tasneem Sumaiya","photoUrl":"","userId":"05522463354673958724"}},"outputId":"c363bccb-f50f-4a3f-89de-9e3893f8bc5a"},"source":["image_counts =[13, 101, 101, 101, 101, 101, 101, 101, 101, 101]\n","\n","image_counts"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[13, 101, 101, 101, 101, 101, 101, 101, 101, 101]"]},"metadata":{"tags":[]},"execution_count":570}]},{"cell_type":"code","metadata":{"id":"Gj7RL5nAFjlI"},"source":["label_names = list(train_generator.class_indices.keys())\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hT6eSRNTvS2O"},"source":["def save_adv_images(advs_jsma, probs_jsma):\n","  output_folder_root_dir = \"/content/drive/MyDrive/Research/GTZAN_Adversarial/jsma_output\"\n","  label_names = list(test_generator.class_indices.keys())\n","\n","  for index,image in enumerate(advs_jsma):\n","    image_resize = image*255 \n","    # print(f\"label {probs_jsma[index]}\")\n","    if image_counts[probs_jsma[index]] < 101:\n","      if(train_generator.classes[index] != probs_jsma[index]):\n","        image_name = str(image_counts[probs_jsma[index]])+'.png'\n","        image_dir = os.path.join(output_folder_root_dir, label_names[probs_jsma[index]])\n","        if not os.path.exists(image_dir):\n","          os.makedirs(image_dir)\n","        image_path = os.path.join(image_dir,image_name)\n","        isWritten = cv2.imwrite(image_path, image_resize)\n","        if isWritten:\n","          print(f'Image {index} is successfully saved in folder {label_names[probs_jsma[index]]}')\n","          print(f'Actual label {label_names[train_generator.classes[index]]}')\n","          image_counts[probs_jsma[index]] += 1\n","      "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YpTfFdQFwLr-"},"source":["save_adv_images(advs_jsma, preds_jsma )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Zn_PUG3ka4Xh"},"source":[""],"execution_count":null,"outputs":[]}]}